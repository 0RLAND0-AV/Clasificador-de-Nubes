"""
CloudClassify13 - Generador de Dataset Aumentado (OFFLINE AUGMENTATION)
========================================================================

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ADVERTENCIA IMPORTANTE - NO USAR ESTE SCRIPT ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

Este script NO debe ejecutarse en el proyecto actual porque:

‚ùå PROBLEMA: DATA LEAKAGE
--------------------------
1. Genera im√°genes aumentadas ANTES del split train/val/test
2. Im√°genes similares terminan en diferentes splits
3. El modelo "ve" la misma nube en train, validation y test
4. Accuracy cae de 43.75% a 22-28% (comprobado experimentalmente)

‚ùå RESULTADOS EXPERIMENTALES:
-----------------------------
- Sin augmentation:        37.5% accuracy (baseline)
- Offline aug (10x):       22.95% accuracy ‚Üê PEOR
- Offline aug (5x):        28.28% accuracy ‚Üê PEOR  
- Online aug (recomendado): 43.75% accuracy ‚Üê MEJOR ‚úÖ

‚úÖ ALTERNATIVA CORRECTA:
------------------------
Usar ONLINE AUGMENTATION (ya implementado en dataset.py):
- Transformaciones se aplican durante el entrenamiento
- Split se hace ANTES de la augmentaci√≥n
- Cada √©poca ve variaciones diferentes
- NO hay data leakage

üìö M√ÅS INFORMACI√ìN:
-------------------
Ver: ADVERTENCIA_AUGMENTATION.md para explicaci√≥n detallada

üîí RAZ√ìN DE EXISTENCIA:
------------------------
Este archivo se mantiene SOLO como:
1. Referencia educativa sobre data leakage
2. Ejemplo de qu√© NO hacer en ML
3. Documentaci√≥n de experimentos fallidos

‚ö†Ô∏è NO EJECUTAR: python augment_dataset.py
‚úÖ USAR EN SU LUGAR: dataset.py (online augmentation)

========================================================================

Uso (NO RECOMENDADO):
    python augment_dataset.py --multiplier 10
"""

import argparse
from pathlib import Path
from PIL import Image
import random
from tqdm import tqdm

from torchvision import transforms
from config import DATA_DIR, IMAGE_SIZE, CLASS_NAMES


def get_augmentation_transforms():
    """
    Transformaciones CONSERVADORAS para data augmentation.
    Prioriza preservar caracter√≠sticas de las nubes.
    """
    return transforms.Compose([
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        # Solo transformaciones geom√©tricas suaves
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),  # Reducido de 30
        # Sin cambios de color agresivos
        transforms.ColorJitter(
            brightness=0.15,   # Muy reducido
            contrast=0.15,     # Muy reducido
            saturation=0.0,    # Desactivado
            hue=0.0           # Desactivado
        ),
        # Convertir a PIL para guardar
        transforms.ToPILImage() if False else lambda x: x,  # No-op, ya es PIL
    ])


def augment_dataset(multiplier=10, output_suffix='_augmented'):
    """
    Genera versiones aumentadas del dataset.
    
    Args:
        multiplier: Cu√°ntas versiones generar por imagen original
        output_suffix: Sufijo para carpetas de salida
    """
    data_dir = Path(DATA_DIR)
    augment_transform = get_augmentation_transforms()
    
    print("=" * 70)
    print("GENERADOR DE DATASET AUMENTADO")
    print("=" * 70)
    print(f"Directorio base: {data_dir}")
    print(f"Multiplicador: {multiplier}x por imagen")
    print(f"Clases: {len(CLASS_NAMES)}")
    print("=" * 70 + "\n")
    
    total_generated = 0
    
    for class_name in CLASS_NAMES:
        class_dir = data_dir / class_name
        
        if not class_dir.exists():
            print(f"‚ö† Clase {class_name} no encontrada, saltando...")
            continue
        
        # Obtener im√°genes originales
        image_files = [
            f for f in class_dir.iterdir()
            if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']
            and not f.stem.endswith('_aug')  # No aumentar im√°genes ya aumentadas
        ]
        
        if not image_files:
            print(f"‚ö† Clase {class_name} sin im√°genes, saltando...")
            continue
        
        print(f"\nüìÇ Procesando clase: {class_name}")
        print(f"   Im√°genes originales: {len(image_files)}")
        print(f"   Generando {len(image_files) * multiplier} im√°genes...")
        
        class_generated = 0
        
        for img_file in tqdm(image_files, desc=f"  {class_name}"):
            try:
                # Cargar imagen original
                original_img = Image.open(img_file).convert('RGB')
                
                # Generar versiones aumentadas
                for i in range(multiplier):
                    # Aplicar transformaciones
                    augmented_img = augment_transform(original_img)
                    
                    # Guardar con nombre √∫nico
                    new_name = f"{img_file.stem}_aug{i:03d}{img_file.suffix}"
                    output_path = class_dir / new_name
                    
                    # Convertir tensor a PIL si es necesario
                    if hasattr(augmented_img, 'numpy'):
                        # Es tensor, no guardamos (esto no deber√≠a pasar con estas transforms)
                        pass
                    else:
                        augmented_img.save(output_path, quality=95)
                        class_generated += 1
                
            except Exception as e:
                print(f"\n   ‚úó Error procesando {img_file.name}: {e}")
                continue
        
        total_generated += class_generated
        print(f"   ‚úì Generadas: {class_generated} im√°genes")
    
    print("\n" + "=" * 70)
    print(f"‚úì COMPLETADO")
    print(f"Total de im√°genes generadas: {total_generated}")
    print(f"Ahora puedes reentrenar el modelo con m√°s datos.")
    print("=" * 70)


def clean_augmented_images():
    """
    Elimina todas las im√°genes aumentadas (con _aug en el nombre).
    """
    data_dir = Path(DATA_DIR)
    
    print("\n‚ö† LIMPIEZA DE IM√ÅGENES AUMENTADAS")
    print("=" * 70)
    
    total_deleted = 0
    
    for class_name in CLASS_NAMES:
        class_dir = data_dir / class_name
        
        if not class_dir.exists():
            continue
        
        aug_files = [
            f for f in class_dir.iterdir()
            if f.stem.endswith('_aug') or '_aug' in f.stem
        ]
        
        if aug_files:
            print(f"üóëÔ∏è  {class_name}: {len(aug_files)} archivos")
            for f in aug_files:
                f.unlink()
                total_deleted += 1
    
    print(f"\n‚úì Eliminadas {total_deleted} im√°genes aumentadas")
    print("=" * 70)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Genera dataset aumentado")
    parser.add_argument(
        '--multiplier',
        type=int,
        default=10,
        help='Cu√°ntas versiones aumentadas generar por imagen (default: 10)'
    )
    parser.add_argument(
        '--clean',
        action='store_true',
        help='Eliminar im√°genes aumentadas existentes'
    )
    
    args = parser.parse_args()
    
    if args.clean:
        confirm = input("‚ö† ¬øEliminar todas las im√°genes aumentadas? (s/N): ")
        if confirm.lower() == 's':
            clean_augmented_images()
    else:
        augment_dataset(multiplier=args.multiplier)
