# CloudClassify13 - Clasificador de Nubes con CNN

**Proyecto de Grupo #13**  
Universidad: [Tu Universidad]  
Curso: Inteligencia Artificial / Machine Learning  
AÃ±o: 2025

## ğŸ“‹ DescripciÃ³n

CloudClassify13 es un sistema de clasificaciÃ³n automÃ¡tica de tipos de nubes basado en redes neuronales convolucionales (CNN). El proyecto combina un backend de machine learning en PyTorch con una interfaz web HTML/CSS/JavaScript para clasificar imÃ¡genes de nubes en 11 categorÃ­as estÃ¡ndar de la OrganizaciÃ³n MeteorolÃ³gica Mundial (OMM/WMO).

### CaracterÃ­sticas Principales

- âœ… **CNN Custom**: Red neuronal convolucional diseÃ±ada especÃ­ficamente para clasificaciÃ³n de nubes
- âœ… **11 Clases de Nubes**: ClasificaciÃ³n segÃºn estÃ¡ndares WMO/OMM
- âœ… **Interfaz Web**: Carga de imÃ¡genes y visualizaciÃ³n de resultados en tiempo real
- âœ… **API REST**: Endpoints para integraciÃ³n en otras aplicaciones
- âœ… **Pipeline Modular**: CÃ³digo organizado en mÃ³dulos independientes
- âœ… **Data Augmentation**: TÃ©cnicas de aumentaciÃ³n de datos para mejor generalizaciÃ³n
- âœ… **Early Stopping**: PrevenciÃ³n de overfitting durante entrenamiento
- âœ… **GPU/CPU**: Soporte automÃ¡tico para aceleraciÃ³n GPU (CUDA)

## ğŸ—ï¸ Arquitectura

### Clases de Nubes (11 tipos - WMO)

| CÃ³digo | Nombre | Altitud | DescripciÃ³n |
|--------|--------|---------|-------------|
| **Ci** | Cirrus | > 6000m | Nubes altas, finas, cristalinas con forma filamentosa |
| **Cc** | Cirrocumulus | > 6000m | Copos o grupos a gran altitud |
| **Cs** | Cirrostratus | > 6000m | Capas delgadas que producen halos |
| **Ac** | Altocumulus | 2000-6000m | Nubes medianas en racimos |
| **As** | Altostratus | 2000-6000m | Capas grises uniformes |
| **Cu** | Cumulus | < 2000m | Nubes densas con cÃºspides redondeadas |
| **Cb** | Cumulonimbus | < 2000m | Nubes de tormenta con desarrollo vertical |
| **Ns** | Nimbostratus | < 2000m | Capas oscuras que producen lluvia |
| **Sc** | Stratocumulus | < 2000m | Nubes bajas en capas o grupos |
| **St** | Stratus | < 2000m | Capas bajas uniformes |
| **Ct** | Contrails | > 6000m | Estelas de condensaciÃ³n de aviones |

### Arquitectura del Modelo CNN

```
CloudCNN Architecture:
â”œâ”€â”€ Conv Block 1: Conv2d(3, 64) â†’ BatchNorm2d(64) â†’ ReLU â†’ MaxPool2d
â”œâ”€â”€ Conv Block 2: Conv2d(64, 128) â†’ BatchNorm2d(128) â†’ ReLU â†’ MaxPool2d
â”œâ”€â”€ Conv Block 3: Conv2d(128, 256) â†’ BatchNorm2d(256) â†’ ReLU â†’ MaxPool2d
â”œâ”€â”€ Conv Block 4: Conv2d(256, 512) â†’ BatchNorm2d(512) â†’ ReLU â†’ MaxPool2d
â”œâ”€â”€ Flatten: 512 Ã— 14 Ã— 14 = 100,352 features
â”œâ”€â”€ FC1: Linear(100352, 512) â†’ ReLU â†’ Dropout(0.5)
â”œâ”€â”€ FC2: Linear(512, 256) â†’ ReLU â†’ Dropout(0.5)
â”œâ”€â”€ FC3: Linear(256, 128) â†’ ReLU â†’ Dropout(0.5)
â””â”€â”€ Output: Linear(128, 11) â†’ Logits (sin Softmax, se aplica en CrossEntropyLoss)
```

**ParÃ¡metros:**
- Total: ~100,000 parÃ¡metros
- Entrada: 224Ã—224 RGB
- Salida: 11 clases

### Pipeline de Datos

```
Raw Images (224Ã—224 RGB)
    â†“
Transformaciones (Train):
  â€¢ Resize a 224Ã—224
  â€¢ Random Horizontal Flip
  â€¢ Random Rotation (Â±15Â°)
  â€¢ Random Crop
  â€¢ ColorJitter (brightness, contrast, saturation, hue)
  â†“
NormalizaciÃ³n (ImageNet):
  â€¢ mean = [0.485, 0.456, 0.406]
  â€¢ std = [0.229, 0.224, 0.225]
    â†“
Tensores PyTorch
    â†“
DataLoader (Batch size: 32)
    â†“
Modelo CNN
```

### Split de Datos

- **Training (70%)**: Datos de entrenamiento con augmentation
- **Validation (15%)**: Datos de validaciÃ³n sin augmentation
- **Testing (15%)**: EvaluaciÃ³n final

## ğŸ“ Estructura del Proyecto

```
CloudClassify13/
â”œâ”€â”€ config.py                  # ConfiguraciÃ³n centralizada
â”œâ”€â”€ model.py                   # DefiniciÃ³n del modelo CNN
â”œâ”€â”€ dataset.py                 # Carga y procesamiento de datos
â”œâ”€â”€ train.py                   # Pipeline de entrenamiento
â”œâ”€â”€ predict.py                 # Sistema de inferencia
â”œâ”€â”€ app.py                     # Servidor Flask
â”œâ”€â”€ main_train.py              # Script principal
â”œâ”€â”€ requirements.txt           # Dependencias Python
â”œâ”€â”€ README.md                  # Este archivo
â”‚
â”œâ”€â”€ web/                       # Interfaz web
â”‚   â”œâ”€â”€ index.html            # PÃ¡gina principal
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ style.css         # Estilos CSS
â”‚       â””â”€â”€ script.js         # LÃ³gica JavaScript
â”‚
â”œâ”€â”€ data/                      # Datos de entrenamiento
â”‚   â”œâ”€â”€ Ci/                   # ImÃ¡genes de Cirrus
â”‚   â”œâ”€â”€ Cc/                   # ImÃ¡genes de Cirrocumulus
â”‚   â”œâ”€â”€ Cs/                   # ImÃ¡genes de Cirrostratus
â”‚   â”œâ”€â”€ Ac/                   # ImÃ¡genes de Altocumulus
â”‚   â”œâ”€â”€ As/                   # ImÃ¡genes de Altostratus
â”‚   â”œâ”€â”€ Cu/                   # ImÃ¡genes de Cumulus
â”‚   â”œâ”€â”€ Cb/                   # ImÃ¡genes de Cumulonimbus
â”‚   â”œâ”€â”€ Ns/                   # ImÃ¡genes de Nimbostratus
â”‚   â”œâ”€â”€ Sc/                   # ImÃ¡genes de Stratocumulus
â”‚   â”œâ”€â”€ St/                   # ImÃ¡genes de Stratus
â”‚   â””â”€â”€ Ct/                   # ImÃ¡genes de Contrails
â”‚
â”œâ”€â”€ models/                    # Modelos entrenados
â”‚   â”œâ”€â”€ checkpoint_*.pt       # Checkpoints durante entrenamiento
â”‚   â”œâ”€â”€ best_model.pt         # Mejor modelo encontrado
â”‚   â””â”€â”€ training_history.json # HistÃ³rico de entrenamiento
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks (opcional)
â””â”€â”€ uploads/                   # ImÃ¡genes subidas (generado por app.py)
```

## ğŸš€ InstalaciÃ³n

### Requisitos del Sistema

- Python 3.7 o superior
- pip (administrador de paquetes Python)
- Opcional: GPU NVIDIA para aceleraciÃ³n CUDA

### Pasos de InstalaciÃ³n

1. **Clonar/Descargar el proyecto:**
```bash
cd tu/ruta/CloudClassify13
```

2. **Crear entorno virtual (recomendado):**
```bash
# En Windows
python -m venv venv
venv\Scripts\activate

# En Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

4. **Descargar o preparar imÃ¡genes de entrenamiento:**
```bash
# Las imÃ¡genes deben organizarse en estructura:
# data/Ci/*.jpg
# data/Cc/*.jpg
# ... etc
```

## ğŸ“š Uso

### 1. Entrenar el Modelo

**Entrenamiento bÃ¡sico:**
```bash
python main_train.py --mode train
```

**Con parÃ¡metros personalizados:**
```bash
python main_train.py --mode train --epochs 100 --batch-size 16 --lr 0.0005
```

**Opciones disponibles:**
```bash
python main_train.py --mode train --help
```

**ParÃ¡metros:**
- `--epochs`: NÃºmero de Ã©pocas (default: 50)
- `--batch-size`: TamaÃ±o de batch (default: 32)
- `--lr`: Tasa de aprendizaje (default: 0.001)
- `--device`: Dispositivo 'cuda', 'cpu' o 'auto' (default: auto)
- `--verbose`: Salida detallada

**Ejemplo con GPU:**
```bash
python main_train.py --mode train --epochs 100 --device cuda --verbose
```

### 2. Evaluar Modelo

```bash
python main_train.py --mode evaluate --checkpoint models/best_model.pt
```

### 3. Realizar Predicciones

**PredicciÃ³n en imagen Ãºnica:**
```bash
python main_train.py --mode predict --image ruta/a/imagen.jpg
```

**Con checkpoint especÃ­fico:**
```bash
python main_train.py --mode predict --image imagen.jpg --checkpoint models/best_model.pt
```

### 4. Usar Interfaz Web

**Iniciar servidor Flask:**
```bash
python app.py
```

Luego abrir en navegador: `http://localhost:5000`

**CaracterÃ­sticas:**
- Subir imagen via drag-and-drop
- Ver predicciÃ³n en tiempo real
- Ver top-3 predicciones
- Ver descripciÃ³n de tipo de nube
- InformaciÃ³n sobre todas las clases

## ğŸ“Š Resultados Esperados

### MÃ©tricas de Entrenamiento

Durante el entrenamiento, el modelo registra:

```
Epoch 1/50
Train Loss: 2.3945 | Train Acc: 0.1523 | Val Acc: 0.1875
Epoch 2/50
Train Loss: 2.1234 | Train Acc: 0.2456 | Val Acc: 0.2800
...
Epoch 50/50
Train Loss: 0.3421 | Train Acc: 0.8934 | Val Acc: 0.8456
```

### HistÃ³rico de Entrenamiento

Se guarda en `models/training_history.json`:

```json
{
  "epochs": [
    {"epoch": 1, "train_loss": 2.3945, "train_acc": 0.1523, "val_loss": 2.4123, "val_acc": 0.1875},
    {"epoch": 2, "train_loss": 2.1234, "train_acc": 0.2456, "val_loss": 2.2045, "val_acc": 0.2800},
    ...
  ],
  "best_epoch": 45,
  "best_val_acc": 0.8956
}
```

## ğŸ”§ MÃ³dulos del Proyecto

### config.py
ConfiguraciÃ³n centralizada del proyecto:
- Rutas de directorios
- Clases de nubes
- HiperparÃ¡metros del modelo
- ParÃ¡metros de entrenamiento
- ConfiguraciÃ³n de augmentation

### model.py
Define la arquitectura CNN:
- Clase `CloudCNN` con 4 bloques convolucionales
- Batch Normalization
- Dropout para regularizaciÃ³n
- InicializaciÃ³n He

### dataset.py
Pipeline de datos:
- Clase `CloudDataset` para cargar imÃ¡genes
- Transformaciones y augmentation
- DataLoaders para train/val/test
- Split estratificado

### train.py
Sistema de entrenamiento:
- Clase `CloudClassifierTrainer`
- Loop de entrenamiento y validaciÃ³n
- Early stopping
- Guardado de checkpoints
- Optimizadores configurables (Adam, SGD, RMSprop)
- Schedulers de learning rate

### predict.py
Sistema de inferencia:
- Clase `CloudPredictor`
- PredicciÃ³n de imÃ¡genes individuales
- PredicciÃ³n por lotes
- Top-K predicciones
- GeneraciÃ³n de probabilidades

### app.py
Servidor web Flask:
- Ruta `/` para interfaz HTML
- Ruta `/api/predict` POST para clasificaciÃ³n
- Ruta `/api/classes` GET para listar clases
- Ruta `/api/info` GET para metadata
- ValidaciÃ³n de archivos
- Manejo de errores

## ğŸ“ˆ Mejoras Futuras

1. **Mejoras del Modelo:**
   - Transfer Learning (ResNet50, EfficientNet)
   - Vision Transformers (ViT)
   - Ensemble de modelos
   - Pruning y quantization

2. **Mejoras de Datos:**
   - Descargador automÃ¡tico de URLs
   - GeneraciÃ³n sintÃ©tica con GANs
   - Data augmentation avanzada

3. **Interfaz:**
   - VisualizaciÃ³n de heatmaps de atenciÃ³n
   - Historial de predicciones
   - ExportaciÃ³n de reportes
   - Dashboard de mÃ©tricas

4. **ProducciÃ³n:**
   - DockerizaciÃ³n
   - Deployment en nube (AWS, Google Cloud)
   - API REST completa
   - Sistema de cachÃ©

## ğŸ“ Referencias

### Papers de InvestigaciÃ³n
- He, K., et al. (2015). "Deep Residual Learning for Image Recognition" (ResNet)
- Ioffe, S., & Szegedy, C. (2015). "Batch Normalization: Accelerating Deep Network Training"
- Simonyan, K., & Zisserman, A. (2014). "Very Deep Convolutional Networks for Large-Scale Image Recognition" (VGG)

### EstÃ¡ndares MeteorolÃ³gicos
- [WMO Cloud Classification](https://library.wmo.int/index.php)
- [International Cloud Atlas - WMO](https://cloudatlas.wmo.int/)

### Proyectos Base
- [CloudClassification (FastAI)](https://github.com/...)
- [Ground-based Cloud Classification](https://github.com/...)
- [Cloud-Classification-New (PyTorch)](https://github.com/...)

## ğŸ“„ Licencia

Este proyecto estÃ¡ disponible bajo licencia MIT. Ver archivo LICENSE para detalles.

## ğŸ‘¥ Equipo

**Grupo #13 - 2025**

### Integrantes
- [Nombre Estudiante 1]
- [Nombre Estudiante 2]
- [Nombre Estudiante 3]
- [Nombre Estudiante 4]

### Profesor
- [Nombre del Profesor]
- Universidad: [Tu Universidad]
- Curso: [Nombre del Curso]

## ğŸ’¬ Contacto

Para preguntas o sugerencias sobre el proyecto, contactar a:
- Email: [Tu Email]
- GitHub: [Tu GitHub]

## ğŸ™ Agradecimientos

- Agradecemos a la [Universidad] por los recursos y soporte
- Agradecemos a los creadores de PyTorch y Flask
- Agradecemos a la WMO por los estÃ¡ndares de clasificaciÃ³n de nubes

---

**Ãšltima actualizaciÃ³n:** Enero 2025  
**VersiÃ³n:** 1.0.0
