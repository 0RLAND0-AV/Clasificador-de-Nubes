# âš ï¸ ADVERTENCIA: augment_dataset.py

## ğŸš« NO USAR ESTE SCRIPT

El archivo `augment_dataset.py` estÃ¡ incluido en el proyecto **SOLO COMO REFERENCIA EDUCATIVA**.

**NO debe ejecutarse** porque causa problemas graves de data leakage y reduce significativamente el accuracy del modelo.

---

## âŒ Problema: Data Leakage

### Â¿QuÃ© es Data Leakage?

El **data leakage** ocurre cuando informaciÃ³n del conjunto de validaciÃ³n o test "se filtra" al conjunto de entrenamiento, causando que el modelo:
- Aparente mejor rendimiento del real
- Falle al generalizar a datos nuevos
- Memorice variaciones en lugar de aprender patrones

### Â¿CÃ³mo causa leakage `augment_dataset.py`?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 1: AugmentaciÃ³n Offline (augment_dataset.py)          â”‚
â”‚                                                             â”‚
â”‚ Imagen Original:                                            â”‚
â”‚   data/Cu/Cu_001.jpg                                        â”‚
â”‚                                                             â”‚
â”‚ Genera 10 copias aumentadas:                                â”‚
â”‚   data/Cu/Cu_001_aug_0.jpg  (flip horizontal)              â”‚
â”‚   data/Cu/Cu_001_aug_1.jpg  (rotaciÃ³n 10Â°)                 â”‚
â”‚   data/Cu/Cu_001_aug_2.jpg  (brillo +15%)                  â”‚
â”‚   ...                                                       â”‚
â”‚   data/Cu/Cu_001_aug_9.jpg  (combinaciÃ³n)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 2: Split de datos (dataset.py)                        â”‚
â”‚                                                             â”‚
â”‚ Las 11 imÃ¡genes (1 original + 10 aumentadas) se            â”‚
â”‚ distribuyen ALEATORIAMENTE:                                 â”‚
â”‚                                                             â”‚
â”‚   TRAIN:      Cu_001.jpg, Cu_001_aug_2.jpg, Cu_001_aug_5   â”‚
â”‚   VALIDATION: Cu_001_aug_1.jpg, Cu_001_aug_8.jpg           â”‚
â”‚   TEST:       Cu_001_aug_3.jpg                             â”‚
â”‚                                                             â”‚
â”‚ âŒ PROBLEMA: El modelo ve la "misma nube" en train,        â”‚
â”‚             validation y test con pequeÃ±as variaciones      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULTADO: Data Leakage                                     â”‚
â”‚                                                             â”‚
â”‚ â€¢ El modelo "memoriza" las nubes especÃ­ficas               â”‚
â”‚ â€¢ Accuracy en validaciÃ³n es artificialmente alta           â”‚
â”‚ â€¢ Pero falla con imÃ¡genes realmente nuevas                 â”‚
â”‚ â€¢ Accuracy real baja drÃ¡sticamente                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Resultados Experimentales

Probamos `augment_dataset.py` con 10x augmentation en el dataset:

| Experimento | MÃ©todo | ImÃ¡genes | Val Accuracy | Resultado |
|-------------|--------|----------|--------------|-----------|
| **1** | Sin augmentation | 111 | **37.5%** | Baseline |
| **2** | Offline aug (10x) | 1,110 | **22.95%** | âŒ Peor |
| **3** | Offline aug (5x) | 555 | **28.28%** | âŒ Peor |
| **4** | Online aug | 111 | **43.75%** | âœ… Mejor |

**ConclusiÃ³n**: Offline augmentation reduce accuracy en **15-20 puntos porcentuales** por data leakage.

---

## âœ… Alternativa Correcta: Online Augmentation

La **online augmentation** (implementada en `dataset.py`) resuelve el problema:

```python
# dataset.py (YA IMPLEMENTADO)
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),      # 50% probabilidad
    transforms.RandomRotation(15),               # Â±15 grados
    transforms.ColorJitter(
        brightness=0.15,
        contrast=0.15
    ),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
```

### Ventajas de Online Augmentation

| Aspecto | Online (âœ…) | Offline (âŒ) |
|---------|------------|--------------|
| **Timing** | Durante entrenamiento | Antes de entrenar |
| **Almacenamiento** | No usa espacio | Multiplica archivos |
| **Data Leakage** | âŒ No ocurre | âœ… SÃ­ ocurre |
| **Variedad** | Infinita (random cada Ã©poca) | Finita (archivos fijos) |
| **Accuracy** | 43.75% | 22-28% |
| **Split** | Limpio | Contaminado |

### CÃ³mo Funciona Online Augmentation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRENAMIENTO CON ONLINE AUGMENTATION             â”‚
â”‚                                                    â”‚
â”‚ Split ANTES de augmentation:                      â”‚
â”‚   TRAIN:      Cu_001.jpg, Cu_003.jpg, Cu_005.jpg  â”‚
â”‚   VALIDATION: Cu_002.jpg, Cu_006.jpg              â”‚
â”‚   TEST:       Cu_004.jpg                          â”‚
â”‚                                                    â”‚
â”‚ Durante cada Ã©poca:                                â”‚
â”‚   Ã‰poca 1: Cu_001.jpg â†’ flip + rotate 5Â°          â”‚
â”‚   Ã‰poca 2: Cu_001.jpg â†’ NO flip + rotate -12Â°     â”‚
â”‚   Ã‰poca 3: Cu_001.jpg â†’ flip + rotate 3Â° + brillo â”‚
â”‚   ...                                              â”‚
â”‚                                                    â”‚
â”‚ âœ… Validation y Test NUNCA se modifican           â”‚
â”‚ âœ… Train ve variaciones diferentes cada Ã©poca     â”‚
â”‚ âœ… No hay leakage entre splits                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ LecciÃ³n Aprendida

### Â¿Por quÃ© existe `augment_dataset.py` en el proyecto?

1. **HistÃ³rico**: Se creÃ³ inicialmente para aumentar el dataset pequeÃ±o
2. **Experimental**: Se probÃ³ como alternativa rÃ¡pida
3. **Educativo**: Se mantiene para mostrar el problema de data leakage
4. **Advertencia**: Ejemplo de quÃ© NO hacer en ML

### Â¿CuÃ¡ndo podrÃ­a ser Ãºtil offline augmentation?

**SOLO en casos muy especÃ­ficos**:
- Dataset ya estÃ¡ dividido manualmente en train/val/test
- Augmentation se aplica SOLO a train, nunca a val/test
- Se necesita pre-procesar una vez por eficiencia computacional
- Se tiene control total del pipeline

**En nuestro caso**: NO aplica porque `dataset.py` hace split automÃ¡tico.

---

## ğŸ“ Recomendaciones

### Si necesitas mÃ¡s datos:

1. **OpciÃ³n A (Mejor)**: Agregar imÃ¡genes reales
   ```bash
   # Buscar datasets pÃºblicos:
   # - SWIM-CCSN Cloud Dataset
   # - MGCD (Multimodal Ground-based Cloud Dataset)
   # - CloudSeg Dataset
   ```

2. **OpciÃ³n B (Ya implementada)**: Usar online augmentation
   ```python
   # Ya estÃ¡ en dataset.py, no requiere cambios
   ```

3. **OpciÃ³n C (NO recomendada)**: Transfer Learning
   ```python
   # Usar modelo pre-entrenado (ResNet, VGG, EfficientNet)
   # Requiere modificar model.py
   ```

### Si quieres experimentar con augmentation:

```python
# Modificar dataset.py (lÃ­neas 30-40)
# Aumentar intensidad de transformaciones:

transforms.RandomHorizontalFlip(p=0.7),      # MÃ¡s agresivo
transforms.RandomRotation(25),               # Mayor rotaciÃ³n
transforms.ColorJitter(
    brightness=0.25,                         # Mayor variaciÃ³n
    contrast=0.25,
    saturation=0.15,
    hue=0.05
),
transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Agregar
```

---

## ğŸ” CÃ³mo Detectar Data Leakage

### SÃ­ntomas:
- âœ… Accuracy de entrenamiento: 95%
- âŒ Accuracy de validaciÃ³n: 90%
- âŒ Accuracy con imÃ¡genes nuevas: 25%

### DiagnÃ³stico:
```python
# Verificar si hay imÃ¡genes similares entre splits
import os
from PIL import Image
import imagehash

def check_leakage(data_dir):
    hashes = {}
    for split in ['train', 'val', 'test']:
        for img_path in get_images(split):
            img = Image.open(img_path)
            h = imagehash.average_hash(img)
            if h in hashes:
                print(f"âš ï¸ LEAKAGE: {img_path} similar a {hashes[h]}")
            hashes[h] = img_path
```

---

## ğŸ“š Referencias

- [Data Leakage in Machine Learning](https://machinelearningmastery.com/data-leakage-machine-learning/)
- [Data Augmentation Best Practices](https://www.tensorflow.org/tutorials/images/data_augmentation)
- [Common ML Mistakes - Data Leakage](https://towardsdatascience.com/data-leakage-in-machine-learning-how-it-can-be-detected-and-minimize-the-risk-8ef4e3a97562)

---

## âœ… Resumen

| Â¿Usar `augment_dataset.py`? | âŒ **NO** |
|-----------------------------|-----------|
| **RazÃ³n** | Causa data leakage |
| **Impacto** | Reduce accuracy 15-20% |
| **Alternativa** | Online augmentation (ya implementado) |
| **UbicaciÃ³n** | `dataset.py` lÃ­neas 30-50 |
| **Estado del script** | Mantener solo como referencia |

**Mensaje final**: Si ves `augment_dataset.py`, **no lo ejecutes**. El proyecto ya tiene la soluciÃ³n correcta implementada.
