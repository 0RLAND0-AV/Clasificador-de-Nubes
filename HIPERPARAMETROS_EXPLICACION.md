# ğŸ“˜ ExplicaciÃ³n de HiperparÃ¡metros - CloudClassify13

## ğŸ¯ Â¿QuÃ© son los HiperparÃ¡metros?

Los hiperparÃ¡metros son **configuraciones que tÃº decides ANTES** de entrenar el modelo. A diferencia de los parÃ¡metros del modelo (pesos y sesgos que se aprenden automÃ¡ticamente), **tÃº controlas los hiperparÃ¡metros** para afectar cÃ³mo aprende la red.

---

## ğŸ”§ HiperparÃ¡metros Principales

### 1. BATCH_SIZE (TamaÃ±o del Lote)

**Â¿QuÃ© es?**  
NÃºmero de imÃ¡genes que el modelo procesa **simultÃ¡neamente** antes de actualizar sus pesos.

```python
BATCH_SIZE = 16  # Procesa 16 imÃ¡genes a la vez
```

#### ğŸ“Š AnalogÃ­a
Imagina que estudias para un examen:
- **Batch pequeÃ±o (8-16)**: Lees 1 pÃ¡gina y haces resumen inmediatamente
- **Batch grande (32-64)**: Lees 10 pÃ¡ginas y luego haces resumen de todo

#### Efectos de Diferentes Valores

| Valor | Efecto | Ventajas | Desventajas | Uso Recomendado |
|-------|--------|----------|-------------|-----------------|
| **4-8** | Muy pequeÃ±o | âœ… Menos memoria GPU<br>âœ… Actualizaciones frecuentes<br>âœ… Escapa mÃ­nimos locales | âŒ Entrenamiento inestable<br>âŒ Muy ruidoso<br>âŒ MÃ¡s lento | GPU pequeÃ±a (2GB VRAM) |
| **16** â­ | PequeÃ±o | âœ… Buen balance<br>âœ… Funciona con datasets pequeÃ±os<br>âœ… RegularizaciÃ³n implÃ­cita | âŒ Un poco ruidoso | **Dataset pequeÃ±o (111 imgs)** â† TU CASO |
| **32** | Medio | âœ… Entrenamiento estable<br>âœ… Buen compromiso | âŒ Necesita mÃ¡s memoria<br>âŒ Puede sobreajustar con pocos datos | Dataset mediano (500-1000 imgs) |
| **64-128** | Grande | âœ… Muy estable<br>âœ… RÃ¡pido por Ã©poca | âŒ Mucha memoria GPU<br>âŒ Puede quedar atascado<br>âŒ Sobreajuste | Dataset grande (5000+ imgs) |
| **1** | Extremo | âš ï¸ Actualiza con cada imagen | âŒ Muy inestable<br>âŒ No aprovecha paralelismo | âŒ NO usar |
| **>128** | Extremo | âš ï¸ Procesa muchas imÃ¡genes | âŒ Memoria insuficiente<br>âŒ Gradientes muy suaves | âŒ NO usar en PC normal |

#### ğŸ§ª Particiones de Equivalencia para BATCH_SIZE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARTICIONES DE EQUIVALENCIA - BATCH_SIZE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InvÃ¡lidos      â”‚ < 1                 â”‚ âŒ ERROR: No tiene sentidoâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy PequeÃ±o    â”‚ 1-7                 â”‚ âš ï¸ Demasiado ruidoso      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PequeÃ±o âœ…     â”‚ 8-16                â”‚ âœ… Ã“PTIMO para datos<111  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medio          â”‚ 17-48               â”‚ âœ… BUENO para datos<1000  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Grande         â”‚ 49-128              â”‚ âœ… BUENO para datos>5000  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Grande âš ï¸  â”‚ >128                â”‚ âš ï¸ CUDA Out of Memory     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Por quÃ© cambiaste de 32 a 16:

**ANTES (32)**:
```
Dataset: 111 imÃ¡genes
Train: 77 imÃ¡genes â†’ 77/32 = 2.4 batches por Ã©poca
                   â†’ Solo 2 actualizaciones de pesos
```
âŒ Muy pocas actualizaciones para aprender bien

**AHORA (16)**:
```
Dataset: 111 imÃ¡genes  
Train: 77 imÃ¡genes â†’ 77/16 = 4.8 batches por Ã©poca
                   â†’ 4-5 actualizaciones de pesos
```
âœ… MÃ¡s actualizaciones = mejor aprendizaje

---

### 2. LEARNING_RATE (Tasa de Aprendizaje)

**Â¿QuÃ© es?**  
QuÃ© tan grande es el "paso" que da el modelo al actualizar sus pesos.

```python
LEARNING_RATE = 0.0005  # Pasos pequeÃ±os y cuidadosos
```

#### ğŸ“Š AnalogÃ­a
Imaginas que estÃ¡s bajando una montaÃ±a con los ojos vendados:
- **LR alto (0.01)**: Das pasos GRANDES â†’ RÃ¡pido pero peligroso (puedes caerte)
- **LR bajo (0.0001)**: Das pasos PEQUEÃ‘OS â†’ Seguro pero lento
- **LR Ã³ptimo (0.0005)**: Pasos medianos â†’ Equilibrio perfecto

#### Efectos Visuales

```
LEARNING RATE MUY ALTO (0.1):
Loss
  â”‚     â•±â•²     â•±â•²     â•±â•²
  â”‚    â•±  â•²   â•±  â•²   â•±  â•²
  â”‚   â•±    â•² â•±    â•² â•±    â•²
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰poca
  âŒ Oscila y nunca converge (salta demasiado)


LEARNING RATE Ã“PTIMO (0.0005):
Loss
  â”‚â•²
  â”‚ â•²___
  â”‚     â•²___
  â”‚         â•²___
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰poca
  âœ… Desciende suavemente al mÃ­nimo


LEARNING RATE MUY BAJO (0.00001):
Loss
  â”‚â•²
  â”‚ â•²
  â”‚  â•²
  â”‚   â•²
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰poca
  âš ï¸ Muy lento, tarda 1000 Ã©pocas
```

#### ğŸ§ª Particiones de Equivalencia para LEARNING_RATE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARTICIONES DE EQUIVALENCIA - LEARNING_RATE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InvÃ¡lido       â”‚ < 0                 â”‚ âŒ ERROR: Negativo sube   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Bajo       â”‚ 0.00001-0.0001      â”‚ âš ï¸ Demasiado lento        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bajo âœ…        â”‚ 0.0001-0.0005       â”‚ âœ… Ã“PTIMO: Estable        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medio          â”‚ 0.0005-0.002        â”‚ âœ… BUENO: RÃ¡pido          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Alto âš ï¸        â”‚ 0.002-0.01          â”‚ âš ï¸ Puede oscilar          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Alto âŒ    â”‚ > 0.01              â”‚ âŒ Diverge, no converge   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Valor | Comportamiento | Resultado |
|-------|----------------|-----------|
| **0.00001** | Pasos minÃºsculos | â±ï¸ Tarda 1000 Ã©pocas en aprender |
| **0.0001** | Pasos pequeÃ±os | âœ… Estable pero lento |
| **0.0005** â­ | Pasos medianos | âœ… **Ã“PTIMO: Equilibrio perfecto** |
| **0.001** | Pasos normales | âœ… Funciona bien en la mayorÃ­a |
| **0.01** | Pasos grandes | âš ï¸ Oscila, puede no converger |
| **0.1** | Pasos enormes | âŒ Diverge completamente |
| **Negativo** | Sube en vez de bajar | âŒ ERROR: El modelo empeora |

#### Por quÃ© cambiaste de 0.001 a 0.0005:

**ANTES (0.001)**:
```
Ã‰poca 1: Loss = 2.5
Ã‰poca 2: Loss = 1.8  (bajÃ³ 0.7)
Ã‰poca 3: Loss = 1.9  (Â¡subiÃ³!) â† Oscila
Ã‰poca 4: Loss = 1.7
```
âš ï¸ Oscilaba porque daba pasos muy grandes

**AHORA (0.0005)**:
```
Ã‰poca 1: Loss = 2.5
Ã‰poca 2: Loss = 2.1  (bajÃ³ 0.4)
Ã‰poca 3: Loss = 1.8  (bajÃ³ 0.3)
Ã‰poca 4: Loss = 1.6  (bajÃ³ 0.2) â† Descenso suave
```
âœ… Descenso suave y constante

---

### 3. DROPOUT_RATE (Tasa de Dropout)

**Â¿QuÃ© es?**  
Porcentaje de neuronas que se "apagan" aleatoriamente durante el entrenamiento para evitar overfitting.

```python
DROPOUT_RATE = 0.6  # Apaga el 60% de neuronas aleatoriamente
```

#### ğŸ“Š AnalogÃ­a
Imagina un equipo de fÃºtbol practicando:
- **Dropout 0.0**: Todos juegan siempre â†’ Se acostumbran mucho entre ellos (overfitting)
- **Dropout 0.6**: Solo 4 de 10 jugadores por entrenamiento â†’ Aprenden a adaptarse
- **Dropout 0.9**: Solo 1 jugador entrena â†’ No pueden aprender nada

#### Efectos Visuales

```
DROPOUT = 0.0 (Sin dropout):
Train Accuracy: 99% âœ…
Val Accuracy:   40% âŒ  â† OVERFITTING
â””â”€ MemorizÃ³ el dataset pero no generaliza


DROPOUT = 0.6 (Ã“ptimo):
Train Accuracy: 75% âœ…
Val Accuracy:   44% âœ…  â† GENERALIZA BIEN
â””â”€ AprendiÃ³ patrones generales


DROPOUT = 0.9 (Demasiado alto):
Train Accuracy: 30% âŒ
Val Accuracy:   28% âŒ  â† UNDERFITTING
â””â”€ No pudo aprender nada
```

#### ğŸ§ª Particiones de Equivalencia para DROPOUT_RATE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARTICIONES DE EQUIVALENCIA - DROPOUT_RATE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InvÃ¡lido       â”‚ < 0 o > 1           â”‚ âŒ ERROR: Debe ser 0-1    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sin Dropout    â”‚ 0.0-0.2             â”‚ âš ï¸ Overfitting probable   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bajo           â”‚ 0.2-0.4             â”‚ âœ… Dataset grande (>5000) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medio          â”‚ 0.4-0.6             â”‚ âœ… Dataset mediano        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Alto âœ…        â”‚ 0.6-0.7             â”‚ âœ… **Dataset pequeÃ±o<500**â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Alto âš ï¸    â”‚ 0.7-0.9             â”‚ âš ï¸ Underfitting posible   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Extremo âŒ     â”‚ 0.9-1.0             â”‚ âŒ Modelo no aprende      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Valor | Neuronas Activas | Resultado |
|-------|------------------|-----------|
| **0.0** | 100% | âŒ Overfitting: Memoriza datos |
| **0.3** | 70% | âœ… Dataset grande (5000+ imgs) |
| **0.5** | 50% | âœ… Dataset mediano (1000 imgs) |
| **0.6** â­ | 40% | âœ… **Dataset pequeÃ±o (111 imgs)** â† TU CASO |
| **0.8** | 20% | âš ï¸ Demasiada regularizaciÃ³n |
| **0.95** | 5% | âŒ Modelo no puede aprender |
| **Negativo** | N/A | âŒ ERROR |

---

### 4. EPOCHS (Ã‰pocas)

**Â¿QuÃ© es?**  
NÃºmero de veces que el modelo ve **TODOS** los datos de entrenamiento.

```python
EPOCHS = 100  # El modelo verÃ¡ las 77 imÃ¡genes 100 veces
```

#### ğŸ“Š AnalogÃ­a
Estudiar para un examen:
- **1 Ã©poca**: Lees el libro una vez
- **10 Ã©pocas**: Lees el libro 10 veces
- **100 Ã©pocas**: Lees el libro 100 veces

#### Efectos

```
POCAS Ã‰POCAS (10):
Accuracy
   â”‚         â•±
   â”‚       â•±
   â”‚     â•±
   â”‚   â•±
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰poca
   âš ï¸ Modelo no terminÃ³ de aprender


Ã‰POCAS Ã“PTIMAS (50-100):
Accuracy
   â”‚       â”Œâ”€â”€â”€â”€
   â”‚     â•±
   â”‚   â•±
   â”‚ â•±
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰poca
   âœ… Modelo aprendiÃ³ y se estabilizÃ³


DEMASIADAS Ã‰POCAS (500):
Accuracy
Train â”‚           â•±â”€â”€â”€â”€
Val   â”‚       â•±â”€â”€â”
      â”‚     â•±    â”‚ â†“ Empeora
      â”‚   â•±      â†“
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰poca
   âŒ Overfitting: MemorizÃ³ datos
```

#### ğŸ§ª Particiones de Equivalencia para EPOCHS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARTICIONES DE EQUIVALENCIA - EPOCHS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InvÃ¡lido       â”‚ < 1                 â”‚ âŒ ERROR: No entrena      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Poco       â”‚ 1-10                â”‚ âš ï¸ No aprende suficiente  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Poco           â”‚ 11-30               â”‚ âš ï¸ Puede no converger     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ã“ptimo âœ…      â”‚ 50-150              â”‚ âœ… BUENO: Con Early Stop  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muchas         â”‚ 150-300             â”‚ âš ï¸ Ineficiente            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Excesivas âŒ   â”‚ > 300               â”‚ âŒ Overfitting garantizadoâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**NOTA**: Con **Early Stopping** (patience=30), el entrenamiento se detiene automÃ¡ticamente cuando no mejora, asÃ­ que puedes poner 100 Ã©pocas sin riesgo.

---

### 5. EARLY_STOPPING_PATIENCE (Paciencia)

**Â¿QuÃ© es?**  
CuÃ¡ntas Ã©pocas esperar sin mejora antes de detener el entrenamiento automÃ¡ticamente.

```python
EARLY_STOPPING_PATIENCE = 30  # Espera 30 Ã©pocas sin mejora
```

#### ğŸ“Š AnalogÃ­a
Esperando a un amigo que llega tarde:
- **Patience = 5**: Esperas 5 minutos y te vas
- **Patience = 30**: Esperas 30 minutos (mÃ¡s paciencia)
- **Patience = 100**: Esperas eternamente (inÃºtil)

#### Efectos

```
PATIENCE = 5 (Muy Bajo):
Ã‰poca 10: Val Acc = 40% (mejor)
Ã‰poca 11: Val Acc = 38%
Ã‰poca 12: Val Acc = 39%
Ã‰poca 13: Val Acc = 38%
Ã‰poca 14: Val Acc = 39%
Ã‰poca 15: Val Acc = 38%
â””â”€ STOP âŒ (Se detuvo muy pronto, podrÃ­a haber mejorado)


PATIENCE = 30 (Ã“ptimo):
Ã‰poca 10: Val Acc = 40% (mejor)
Ã‰poca 11-39: Val Acc = 37-39% (oscilando)
Ã‰poca 40: Val Acc = 44% (Â¡mejorÃ³!) âœ…
â””â”€ ContinuÃ³ y encontrÃ³ mejor modelo
```

#### ğŸ§ª Particiones de Equivalencia para PATIENCE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARTICIONES DE EQUIVALENCIA - EARLY_STOPPING_PATIENCE          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InvÃ¡lido       â”‚ < 1                 â”‚ âŒ ERROR: Detiene al toqueâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Bajo       â”‚ 1-5                 â”‚ âš ï¸ Detiene muy pronto     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bajo           â”‚ 6-15                â”‚ âš ï¸ Puede perder mejoras   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medio âœ…       â”‚ 16-30               â”‚ âœ… Ã“PTIMO: Balance        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Alto           â”‚ 31-50               â”‚ âš ï¸ Desperdicia tiempo     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Muy Alto âŒ    â”‚ > 50                â”‚ âŒ PrÃ¡cticamente sin stop â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Tabla Resumen - Particiones de Equivalencia

| HiperparÃ¡metro | InvÃ¡lido | Muy Bajo | Bajo/Ã“ptimo | Medio | Alto | Muy Alto |
|----------------|----------|----------|-------------|-------|------|----------|
| **BATCH_SIZE** | <1 âŒ | 1-7 âš ï¸ | **8-16 âœ…** | 17-48 | 49-128 | >128 âŒ |
| **LEARNING_RATE** | <0 âŒ | 0.00001 âš ï¸ | **0.0005 âœ…** | 0.001-0.002 | 0.01 âš ï¸ | >0.01 âŒ |
| **DROPOUT_RATE** | <0 o >1 âŒ | 0.0-0.2 âš ï¸ | 0.3-0.5 | **0.6 âœ…** | 0.7-0.8 âš ï¸ | 0.9-1.0 âŒ |
| **EPOCHS** | <1 âŒ | 1-10 âš ï¸ | 11-30 âš ï¸ | **50-150 âœ…** | 150-300 âš ï¸ | >300 âŒ |
| **PATIENCE** | <1 âŒ | 1-5 âš ï¸ | 6-15 âš ï¸ | **16-30 âœ…** | 31-50 âš ï¸ | >50 âŒ |

âœ… = Valores Ã³ptimos para tu caso (111 imÃ¡genes)

---

## ğŸ’¡ ConfiguraciÃ³n Actual Explicada

```python
# ==================== TU CONFIGURACIÃ“N ACTUAL ====================

BATCH_SIZE = 16
# âœ… Ã“PTIMO para 111 imÃ¡genes
# â†’ 77 train / 16 = ~5 batches por Ã©poca
# â†’ 5 actualizaciones de pesos por Ã©poca
# Antes era 32 â†’ Solo 2 actualizaciones (muy poco)

LEARNING_RATE = 0.0005
# âœ… Ã“PTIMO: Pasos pequeÃ±os y estables
# â†’ Descenso suave sin oscilaciones
# Antes era 0.001 â†’ Oscilaba demasiado

DROPOUT_RATE = 0.6
# âœ… Ã“PTIMO para dataset pequeÃ±o
# â†’ Apaga 60% de neuronas aleatoriamente
# â†’ Previene overfitting (memorizaciÃ³n)
# Antes era 0.5 â†’ No era suficiente

EPOCHS = 100
# âœ… SUFICIENTE con early stopping
# â†’ Permite entrenar completamente
# â†’ Early stopping lo detiene si no mejora

EARLY_STOPPING_PATIENCE = 30
# âœ… Ã“PTIMO: Da tiempo suficiente
# â†’ Espera 30 Ã©pocas sin mejora
# â†’ No detiene prematuramente
# Antes era 25 â†’ A veces detenÃ­a muy pronto
```

---

## ğŸ¯ Â¿QuÃ© pasa si cambias los valores?

### Escenario 1: BATCH_SIZE = 4 (Muy pequeÃ±o)
```
âœ… Ventajas:
- Funciona en GPU pequeÃ±a (2GB)
- 77/4 = 19 actualizaciones por Ã©poca (muchas)

âŒ Desventajas:
- Entrenamiento muy ruidoso e inestable
- Loss oscila mucho
- Tarda mÃ¡s tiempo
- Puede no converger
```

### Escenario 2: BATCH_SIZE = 64 (Muy grande)
```
âŒ Problemas:
- CUDA out of memory (GPU insuficiente)
- 77/64 = 1.2 batches por Ã©poca (muy poco)
- Solo 1 actualizaciÃ³n por Ã©poca
- No aprende nada
- Overfitting garantizado
```

### Escenario 3: LEARNING_RATE = 0.01 (Muy alto)
```
âŒ Resultado:
Ã‰poca 1: Loss = 2.5
Ã‰poca 2: Loss = 3.8  â† SubiÃ³ en vez de bajar
Ã‰poca 3: Loss = 1.2
Ã‰poca 4: Loss = 4.1  â† Oscila violentamente
Ã‰poca 5: Loss = 2.7
â””â”€ DIVERGE: Nunca converge
```

### Escenario 4: LEARNING_RATE = 0.00001 (Muy bajo)
```
â±ï¸ Resultado:
Ã‰poca 1: Loss = 2.5000
Ã‰poca 2: Loss = 2.4995  â† Baja muy poco
Ã‰poca 3: Loss = 2.4990
Ã‰poca 4: Loss = 2.4985
...
Ã‰poca 100: Loss = 2.4500 â† TodavÃ­a no terminÃ³
â””â”€ LENTO: TardarÃ­a 1000 Ã©pocas
```

### Escenario 5: DROPOUT = 0.0 (Sin regularizaciÃ³n)
```
âŒ Resultado:
Train Accuracy: 99% âœ… (Aparentemente perfecto)
Val Accuracy:   25% âŒ (Peor que azar)

â””â”€ OVERFITTING: MemorizÃ³ las 77 imÃ¡genes
   pero no puede clasificar nuevas imÃ¡genes
```

### Escenario 6: DROPOUT = 0.9 (Demasiada regularizaciÃ³n)
```
âŒ Resultado:
Train Accuracy: 20%
Val Accuracy:   18%

â””â”€ UNDERFITTING: El 90% de neuronas apagadas
   no deja aprender al modelo
```

---

## ğŸ“Š Valores Negativos/Extremos

### BATCH_SIZE Negativo o 0
```python
BATCH_SIZE = -16  # âŒ ERROR
BATCH_SIZE = 0    # âŒ ERROR

# Python lanza excepciÃ³n:
ValueError: batch_size should be a positive integer value, but got batch_size=-16
```

### LEARNING_RATE Negativo
```python
LEARNING_RATE = -0.001  # âŒ ERROR CONCEPTUAL

# QuÃ© pasa:
# El gradiente se invierte
# El modelo SUBE en vez de BAJAR
# Loss aumenta en vez de disminuir
# 
# Ã‰poca 1: Loss = 2.5
# Ã‰poca 2: Loss = 5.8  â† PEOR
# Ã‰poca 3: Loss = 12.3 â† PEOR
# Ã‰poca 4: Loss = 45.7 â† PEOR
```

### DROPOUT Fuera de Rango
```python
DROPOUT_RATE = 1.5   # âŒ ERROR
DROPOUT_RATE = -0.3  # âŒ ERROR

# Python lanza excepciÃ³n:
ValueError: dropout probability has to be between 0 and 1, but got 1.5
```

### EPOCHS = 0 o Negativo
```python
EPOCHS = 0   # âŒ No entrena nada
EPOCHS = -10 # âŒ ERROR

# El modelo no se entrena
# Accuracy permanece aleatoria (~9% para 11 clases)
```

---

## ğŸ“ Recomendaciones Finales

### Para TU proyecto (111 imÃ¡genes):
```python
# âœ… CONFIGURACIÃ“N Ã“PTIMA ACTUAL
BATCH_SIZE = 16              # Balance perfecto
LEARNING_RATE = 0.0005       # Estable
DROPOUT_RATE = 0.6           # Previene overfitting
EPOCHS = 100                 # Con early stopping
EARLY_STOPPING_PATIENCE = 30 # Tiempo suficiente
```

### Si tuvieras MÃS datos (1000 imÃ¡genes):
```python
BATCH_SIZE = 32              # MÃ¡s estable
LEARNING_RATE = 0.001        # MÃ¡s rÃ¡pido
DROPOUT_RATE = 0.5           # Menos regularizaciÃ³n
EPOCHS = 150
EARLY_STOPPING_PATIENCE = 20
```

### Si tuvieras MUCHOS datos (10,000 imÃ¡genes):
```python
BATCH_SIZE = 64
LEARNING_RATE = 0.001
DROPOUT_RATE = 0.3
EPOCHS = 200
EARLY_STOPPING_PATIENCE = 15
```

---

## ğŸ“š Resumen Ejecutivo

1. **BATCH_SIZE**: CuÃ¡ntas imÃ¡genes procesa a la vez
   - PequeÃ±o (16) â†’ MÃ¡s actualizaciones â†’ Mejor para pocos datos âœ…

2. **LEARNING_RATE**: TamaÃ±o del paso al aprender
   - Bajo (0.0005) â†’ Aprendizaje lento pero estable âœ…

3. **DROPOUT**: Neuronas apagadas aleatoriamente
   - Alto (0.6) â†’ Previene memorizaciÃ³n con pocos datos âœ…

4. **EPOCHS**: Veces que ve todos los datos
   - 100 es suficiente con early stopping âœ…

5. **PATIENCE**: Ã‰pocas a esperar sin mejora
   - 30 da tiempo suficiente para mejorar âœ…

**Tu configuraciÃ³n actual es Ã“PTIMA para 111 imÃ¡genes** â­
